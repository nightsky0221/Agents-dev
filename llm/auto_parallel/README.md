# è‡ªåŠ¨å¹¶è¡Œä½¿ç”¨è¯´æ˜
æœ¬ README è¯¦ç»†ä»‹ç»äº†å¦‚ä½•ä½¿ç”¨è‡ªåŠ¨å¹¶è¡Œè¿›è¡Œå¤§æ¨¡å‹çš„é¢„è®­ç»ƒã€SFTï¼ˆç›‘ç£å¾®è°ƒï¼‰ã€LoRAï¼ˆä½ç§©é€‚åº”ï¼‰ã€DPOï¼ˆç›´æ¥åå¥½ä¼˜åŒ–ï¼‰ä»¥åŠæ¨ç†ã€‚

## ç›®å½•
- [è‡ªåŠ¨å¹¶è¡Œä½¿ç”¨è¯´æ˜](#è‡ªåŠ¨å¹¶è¡Œä½¿ç”¨è¯´æ˜)
  - [ç›®å½•](#ç›®å½•)
  - [å½“å‰æ”¯æŒæ¨¡å‹](#å½“å‰æ”¯æŒæ¨¡å‹)
  - [ç¯å¢ƒå‡†å¤‡](#ç¯å¢ƒå‡†å¤‡)
  - [é¢„è®­ç»ƒ](#é¢„è®­ç»ƒ)
    - [æ•°æ®å‡†å¤‡](#æ•°æ®å‡†å¤‡)
    - [å¯åŠ¨é¢„è®­ç»ƒ](#å¯åŠ¨é¢„è®­ç»ƒ)
  - [ç›‘ç£å¾®è°ƒ(SFT)](#ç›‘ç£å¾®è°ƒ sft)
    - [æ•°æ®å‡†å¤‡](#æ•°æ®å‡†å¤‡-1)
    - [å¯åŠ¨å¾®è°ƒ](#å¯åŠ¨å¾®è°ƒ)
  - [ä½ç§©é€‚åº”ï¼ˆLoRAï¼‰](#ä½ç§©é€‚åº” lora)
  - [DPO](#dpo)
  - [æ¨ç†](#æ¨ç†)
    - [åŠ¨æ€å›¾æ¨ç†](#åŠ¨æ€å›¾æ¨ç†)
    - [é™æ€å›¾æ¨ç†](#é™æ€å›¾æ¨ç†)
  - [FAQ](#faq)

## å½“å‰æ”¯æŒæ¨¡å‹
| Model | Pretrain | SFT |  LoRA | DPO |
|-------|----------|-----|-----|-----|
| GPT-3 |    âœ…    |  ğŸš§   |  ğŸš§  | ğŸš§   |
| Llama |    âœ…    |  âœ…   |  âœ…  | âœ…   |
| Qwen  |    âœ…    |  ğŸš§   |  ğŸš§  | ğŸš§   |
| DeepSeek-V3| âœ…   |  ğŸš§   |  ğŸš§  | ğŸš§   |

- âœ…: Supported
- ğŸš§: In Progress

æ³¨ï¼šå½“å‰æä¾›çš„ DeepSeek-v3æ¨¡å‹é…ç½®è„šæœ¬ä¸ºä¸€ä¸ªè§„æ¨¡è¾ƒå°çš„ç¤ºä¾‹ demoï¼ˆè°ƒå°äº†ç½‘ç»œå±‚æ•°ï¼‰ï¼Œä»¥æ”¯æŒåœ¨å•æœº8å¡çš„ç¯å¢ƒä¸‹è¿è¡Œï¼Œå¦‚æœä½ æƒ³è¿è¡Œå®Œæ•´671B è§„æ¨¡çš„ DeepSeek-v3ï¼Œéœ€è¦å°†å±‚æ•°é…ç½®ä¸º61å±‚ï¼Œå¹¶å¯¹åº”åœ°è°ƒæ•´å¹¶è¡Œç­–ç•¥ã€‚å½“å‰è‡ªåŠ¨å¹¶è¡Œæä¾›çš„ deepseek-v3ç‰ˆæœ¬ä¸­ï¼Œæš‚æœªé›†æˆ FP8ã€DeepEP ç­‰ä¼˜åŒ–ç­–ç•¥ã€‚

## ç¯å¢ƒå‡†å¤‡

1.å®‰è£… PaddlePaddle æœ€æ–°ç‰ˆæœ¬

é¦–å…ˆï¼Œæ‚¨éœ€è¦å®‰è£…æœ€æ–°çš„`Paddle`ï¼Œ æ¨èä½¿ç”¨`Nightly`ç‰ˆæœ¬ã€‚è®¿é—® [Paddle å®˜ç½‘](https://www.paddlepaddle.org.cn/install/quick?docurl=undefined) è·å–å®‰è£…æŒ‡å¯¼ã€‚

2.Paddle å®‰è£…éªŒè¯

```python
import paddle
print(paddle.utils.run_check())
```
3.å®‰è£… PaddleNLP åŠè‡ªå®šä¹‰ç®—å­

è¯·è®¿é—®[PaddleNLP å®‰è£…æ•™ç¨‹](https://github.com/PaddlePaddle/PaddleNLP/blob/develop/docs/zh/get_started/installation.rst)è·å–å®‰è£…æŒ‡å¯¼ã€‚


## é¢„è®­ç»ƒ

### æ•°æ®å‡†å¤‡

é¡¹ç›®æä¾›äº†é¢„å…ˆå¤„ç†å¥½çš„æ•°æ®æ–¹ä¾¿ç”¨æˆ·æµ‹è¯•æ¨¡å‹ï¼Œä¸‹è½½åˆ° `data` ç›®å½•ä¸‹ï¼š

```shell
mkdir -p data && cd data
wget https://bj.bcebos.com/paddlenlp/models/transformers/llama/data/llama_openwebtext_100k.{bin,idx}
```

### å¯åŠ¨é¢„è®­ç»ƒ

#### GPU å¯åŠ¨é¢„è®­ç»ƒ

- åŠ¨æ€å›¾æ¨¡å¼

```python
# Llama pretrain example
# assume that cur dir is auto_parallel
# cd ${PaddleNLP_Path}/llm/auto_parallel/
python -u  -m paddle.distributed.launch \
    --gpus "0,1,2,3,4,5,6,7"            \
    --log_dir "llama_auto_3d"           \
    ./llama/run_pretrain_auto.py ./llama/pretrain_argument.json
```

è¯¥é…ç½®ä¸‹è¿è¡Œ`facebook/llama-7b`é¢„è®­ç»ƒä»»åŠ¡ï¼Œå¹¶è¡Œç­–ç•¥ä¸º MP2-PP2-DP2ï¼Œåˆ†ç‰‡ç­–ç•¥ä¸º Stage1ã€‚
æ›´å¤šå¯é…ç½®å‚æ•°ï¼Œè¯·å‚è€ƒ`ModelArguments`, `DataArguments`, `PreTrainingArguments`ã€‚

- åŠ¨è½¬é™æ¨¡å¼
<br>è¿½åŠ  `to_static`å‚æ•°

#### XPU å¯åŠ¨é¢„è®­ç»ƒ

é™¤äº† GPUï¼ŒXPU ä¹Ÿæ”¯æŒè‡ªåŠ¨å¹¶è¡Œï¼Œç›®å‰æ”¯æŒ llama æ¨¡å‹ 7b å’Œ 13bï¼Œæ›´å¤šæ¨¡å‹æ”¯æŒæ­£åœ¨å¼€å‘ä¸­ã€‚

ç”¨æˆ·å¯ä»¥ä½¿ç”¨ `PaddleNLP/llm/auto_parallel/llama` ç›®å½•ä¸‹çš„ `run_llama2_7b_xpu.sh` å’Œ `run_llama2_13b_xpu.sh` è„šæœ¬å¯åŠ¨ XPU ä¸Šçš„é¢„è®­ç»ƒä»»åŠ¡ã€‚

```shell
# cd ${PaddleNLP_Path}/llm/auto_parallel/llama
bash run_llama2_7b_xpu.sh
# or
bash run_llama2_13b_xpu.sh
```

Llama 7b å¹¶è¡Œç­–ç•¥ä¸º DP8ï¼Œåˆ†ç‰‡ç­–ç•¥ä¸º Stage1ã€‚Llama 13b å¹¶è¡Œç­–ç•¥ä¸º DP2-PP4ï¼Œåˆ†ç‰‡ç­–ç•¥ä¸º Stage1ã€‚


## ç›‘ç£å¾®è°ƒ(SFT)
### æ•°æ®å‡†å¤‡

é¡¹ç›®æä¾›é¢„å¤„ç†å¥½çš„ç²¾è°ƒæ•°æ®æ–¹ä¾¿ç”¨æˆ·æµ‹è¯•æ¨¡å‹ï¼Œä¸‹è½½å¹¶è§£å‹åˆ°`data`ç›®å½•ä¸‹ï¼š

```shell
wget -O AdvertiseGen.tar.gz https://bj.bcebos.com/paddlenlp/datasets/examples/AdvertiseGen.tar.gz
tar -xvf AdvertiseGen.tar.gz
```

### å¯åŠ¨å¾®è°ƒ

- åŠ¨æ€å›¾æ¨¡å¼
```python
# Llama finetune example
# assume that cur dir is auto_parallel
# cd ${PaddleNLP_Path}/llm/auto_parallel/
python -u -m paddle.distributed.launch \
  --gpus "0,1,2,3,4,5,6,7" \
  ./run_finetune_auto.py ./llama/finetune_argument.json
```
è¯¥é…ç½®ä¸‹è¿è¡Œ`Meta-Llama-3.1-8B-Instruct`ä»»åŠ¡ï¼Œå¹¶è¡Œç­–ç•¥ä¸º MP2-PP2-DP2ï¼Œåˆ†ç‰‡ç­–ç•¥ä¸º Stage2ã€‚
æ›´å¤šå¯é…ç½®å‚æ•°ï¼Œè¯·å‚è€ƒ`GenerateArgument`, `ModelAutoConfig`, `ReftArgument`, `DataConfig`, `SFTAutoConfig`ã€‚

- åŠ¨è½¬é™æ¨¡å¼
<br>è¿½åŠ `to_static`å‚æ•°

## ä½ç§©é€‚åº”ï¼ˆLoRAï¼‰
åœ¨ SFT åŸºç¡€ä¸Šå¯ç”¨ï¼Œå¼€å¯`lora`, `lora_rank`å‚æ•°ã€‚
æ›´å¤šçš„å‚æ•°ï¼Œå¯ä»¥å‚è€ƒ[model_config.py](https://github.com/PaddlePaddle/PaddleNLP/blob/develop/paddlenlp/trl/model_config.py)ã€‚

## DPO
### æ•°æ®å‡†å¤‡
ä¸ºäº†æ–¹ä¾¿æµ‹è¯•ï¼Œæˆ‘ä»¬å°† [ultrafeedback_binarized](https://huggingface.co/datasets/HuggingFaceH4/ultrafeedback_binarized) çš„æ•°æ®é›†å¤„ç†æˆå¯¹åº”çš„æ•°æ®é›†æ ¼å¼ï¼Œå¯ä»¥åœ¨ PaddleNLP/llm ç›®å½•ä¸‹è¿è¡Œï¼š
```shell
wget https://bj.bcebos.com/paddlenlp/datasets/examples/ultrafeedback_binarized.tar.gz
tar -zxvf ultrafeedback_binarized.tar.gz
```

### å¯åŠ¨ DPO è®­ç»ƒ
å¯ä»¥åœ¨ PaddleNLP/llm/auto_parallel/llama ç›®å½•ä¸‹è¿è¡Œï¼š
```shell
bash llama_dpo_with_api.sh
```
åŒæ ·ï¼Œå¯ä»¥é€šè¿‡é…ç½®`to_static`å¼€å…³æ§åˆ¶æ˜¯å¦ä½¿ç”¨åŠ¨è½¬é™æ¨¡å¼ã€‚

## æ¨ç†
æ¨ç†æµç¨‹åŒ…æ‹¬ï¼šåŠ¨æ€å›¾æ¨ç†ï¼ŒåŠ¨è½¬é™å¯¼å‡ºæ¨¡å‹ -> é™æ€å›¾æ¨ç†ã€‚

### åŠ¨æ€å›¾æ¨ç†
å½“å‰è‡ªåŠ¨å¹¶è¡Œä»»åŠ¡ä¿å­˜çš„æ¨¡å‹å‚æ•°å·²æ”¯æŒç”¨äºåŠ¨æ€å›¾æ¨ç†ã€‚ä»¥åŠ¨æ€å›¾è‡ªåŠ¨å¹¶è¡Œè®­ç»ƒï¼ˆDP2-MP2-PP2ï¼‰ä¸ºä¾‹ï¼š
- åˆ†å¸ƒå¼ ckpt åˆå¹¶ä¸ºå•å¡æ¨¡å‹å‚æ•°

```python
import paddle
import paddle.distributed as dist

ckpt_path='/path/for/dist_ckpt'
# offload=1, å‚æ•° offload åˆ° CPUï¼Œå‡å°‘æ˜¾å­˜å ç”¨
# prefix="model" å‚æ•°å¯ç”¨äºè¿‡æ»¤æ‰éæ¨¡å‹å‚æ•°ï¼Œä¾‹å¦‚ optimizer çŠ¶æ€ç­‰
merged_state_dict = dist.checkpoint.load_state_dict.load_merged_state_dict(ckpt_path, offload=1, prefix="model")
paddle.save(merged_state_dict, 'model_state.pdparams')

# ä¸Šè¿°åˆå¹¶çš„æ¨¡å‹å‚æ•°æ ¼å¼ä¸ºPaddleåŸç”Ÿæ ¼å¼ï¼Œå¦‚éœ€è½¬æ¢ä¸ºunified checkpointæ ¼å¼(safetensors)ï¼Œæˆ–éœ€è·å–æ¨¡å‹å‚æ•°çš„indexæ–‡ä»¶ï¼Œç»§ç»­æ‰§è¡Œå¦‚ä¸‹ä»£ç ï¼š
python PaddleNLP/llm/auto_parallel/utils/convert_to_safetensors.py --input_path input_path  [--output_path output_path] [--split_num split_num] [--offload] [--as_safetensors]

# å‚æ•°ä»‹ç»
--input_path: è¾“å…¥çš„å•å¡æ¨¡å‹å‚æ•°è·¯å¾„
--output_path: å¯é€‰ï¼Œè¾“å‡ºæ¨¡å‹å‚æ•°è·¯å¾„ï¼Œé»˜è®¤ä¸º'./temp'
--split_num: å¯é€‰ï¼Œè¾“å‡ºçš„æ¨¡å‹å‚æ•°åˆ†ç‰‡æ•°ï¼Œé»˜è®¤ä¸º 1
--offload: å¯é€‰ï¼Œé€‰é¡¹ç”¨äºæ§åˆ¶æ˜¯å¦å°†å‚æ•° offload åˆ° CPU
--as_safetensors: å¯é€‰ï¼Œé€‰é¡¹ç”¨äºæ§åˆ¶æ˜¯å¦å°†æ¨¡å‹å‚æ•°è½¬æ¢ä¸º safetensors æ ¼å¼
```

- åŠ¨æ€å›¾æ¨ç†
<br>è¯·å‚è€ƒ[å¤§æ¨¡å‹æ¨ç†æ•™ç¨‹](https://github.com/PaddlePaddle/PaddleNLP/blob/develop/llm/docs/predict/inference.md)ã€‚

### é™æ€å›¾æ¨ç†
åŠ¨è½¬é™å¯¼å‡ºæ¨¡å‹ã€é™æ€å›¾æ¨ç†æ­¥éª¤è¯·å‚è€ƒ [LLaMA ç³»åˆ—å¤§æ¨¡å‹è¿è¡Œæ–‡æ¡£](https://github.com/PaddlePaddle/PaddleNLP/blob/develop/llm/docs/predict/llama.md)ã€‚

## FAQ

Q1: å‡ºç° OOM å¦‚ä½•è°ƒæ•´?
- å‡å°‘ batch_size
- å¼€å¯ fuse_attention_ffn, fuse_flash_qkv
