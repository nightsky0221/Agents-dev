import argparse
import glob
import os
import multiprocessing as mp
from pathlib import Path
import re

from until.collect_import_modeling import expand_modeling_imports,remove_imports_and_rewrite,save_results_to_txt
from until.rewrite_child_classes import rewrite_child_classes
from until.rename_identifiers import rename_identifiers

AUTO_GENERATED_MESSAGE = """#                ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨
#           This file was automatically generated from {relative_path}.
#               Do NOT edit this file manually as any edits will be overwritten by the generation of
#             the file from the modular. If any change should be done, please apply the change to the
#                          {short_name} file directly. One of our CI enforces this.
#                ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨
"""

# --- æ ¸å¿ƒè½¬æ¢é€»è¾‘å°è£… ---
def run_converter(file_to_parse_str: str):
    """
    å¯¹å•ä¸ª modular æ–‡ä»¶æ‰§è¡Œå®Œæ•´çš„è½¬æ¢æµç¨‹ã€‚
    è¿™ä¸ªå‡½æ•°æ˜¯å¹¶è¡Œå¤„ç†çš„åŸºæœ¬å•å…ƒã€‚
    """
    print(file_to_parse_str)
    file_to_parse = Path(file_to_parse_str)
    
    # --- åŠ¨æ€ç¡®å®šæ¨¡å‹åç§°å’Œè¾“å‡ºè·¯å¾„ ---
    # å‡è®¾ï¼šç›®æ ‡æ¨¡å‹åå¯ä»¥ä»æ–‡ä»¶åæ¨æ–­ï¼Œä¾‹å¦‚ "modular_qwen2.py" -> "qwen2"
    to_name = file_to_parse.stem.replace("modular_", "")
    # å‡è®¾ï¼šæºæ¨¡å‹ååœ¨æ¨¡å—åŒ–æ–‡ä»¶ä¸­æœ‰å®šä¹‰æˆ–çº¦å®šä¿—æˆï¼ˆè¿™é‡Œæˆ‘ä»¬å…ˆç¡¬ç¼–ç ä¸º "llama" ä½œä¸ºç¤ºä¾‹ï¼‰
    # ä¸€ä¸ªæ›´å¥å£®çš„å®ç°ä¼šä» file_to_parse æ–‡ä»¶å†…å®¹ä¸­è§£æå‡º from_name
    
    # è¾“å‡ºæ–‡ä»¶å°†ä¸è¾“å…¥æ–‡ä»¶åœ¨åŒä¸€ç›®å½•ä¸‹ï¼Œä¾‹å¦‚ "modeling_qwen2.py"
    output_file = file_to_parse.parent / f"modeling_{to_name}.py"
    temp_merged_file = file_to_parse.parent / (output_file.stem + "_temp_merged.py")

    print(f"--- å¼€å§‹è½¬æ¢: {to_name} ---")
    print(f"  è¾“å…¥æ–‡ä»¶: '{file_to_parse}'")
    print(f"  æœ€ç»ˆè¾“å‡º: '{output_file}'")

    # æ­¥éª¤ 1: æ”¶é›†å¹¶å±•å¼€ import
    expanded_code , dependencies,from_name= expand_modeling_imports(file_to_parse)
    #save_results_to_txt(dependencies, "modeling_imports_dependencies.txt")
    #save_results_to_txt(expanded_code, "modeling_imports_results.txt")
    #print(from_name)
    # æ­¥éª¤ 2: é‡å†™å­ç±»å¹¶ç”Ÿæˆä¸­é—´æ–‡ä»¶
    relative_path = re.search(
                    r"(transformers/.*|examples/.*)", os.path.abspath(file_to_parse).replace("\\", "/")
                ).group(1)
    formatted_message=AUTO_GENERATED_MESSAGE.format(relative_path=relative_path, short_name=os.path.basename(relative_path))
    rewrite_child_classes(expanded_code, file_to_parse,formatted_message, temp_merged_file,rename_map={
            "llama": "qwen2"  # åªéœ€è¦æä¾›å°å†™å½¢å¼ï¼
        })
    remove_imports_and_rewrite(temp_merged_file)
    # æ­¥éª¤ 3: å…¨å±€é‡å‘½å
    try:
        merged_code = temp_merged_file.read_text(encoding="utf-8")
        final_code = rename_identifiers(merged_code, from_name, to_name)
        output_file.write_text(final_code, encoding="utf-8")
        print(f"  âœ… è½¬æ¢æˆåŠŸï¼Œæœ€ç»ˆä»£ç å·²å†™å…¥ '{output_file}'ã€‚")
    except FileNotFoundError:
        print(f"  âŒ [é”™è¯¯] æ‰¾ä¸åˆ°ä¸­é—´æ–‡ä»¶ '{temp_merged_file}'ï¼Œæ— æ³•è¿›è¡Œé‡å‘½åã€‚")
    finally:
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        if temp_merged_file.exists():
            temp_merged_file.unlink()
    
    print(f"--- è½¬æ¢ç»“æŸ: {to_name} ---\n")


# --- ä¸»æ‰§è¡Œé€»è¾‘ ---
def main():
    parser = argparse.ArgumentParser(
        description="å°†æ¨¡å—åŒ–çš„æ¨¡å‹å®šä¹‰æ–‡ä»¶ï¼ˆmodular_*.pyï¼‰è½¬æ¢ä¸ºç‹¬ç«‹çš„æ¨¡å‹æ–‡ä»¶ï¼ˆmodeling_*.pyï¼‰ã€‚"
    )
    parser.add_argument(
        "files",
        nargs="*",
        help="è¦è½¬æ¢çš„æ¨¡å—åŒ–æ–‡ä»¶åˆ—è¡¨ï¼ˆå¯é€‰çš„ä½ç½®å‚æ•°ï¼‰ã€‚",
    )
    parser.add_argument(
        "--files-to-parse", "-f",
        dest="files_to_parse", # æ˜ç¡®æŒ‡å®šå­˜å‚¨çš„ç›®çš„åœ°
        default=[], # é»˜è®¤å€¼æ”¹ä¸ºç©ºåˆ—è¡¨
        nargs="+",
        help="è¦è½¬æ¢çš„æ¨¡å—åŒ–æ–‡ä»¶åˆ—è¡¨ã€‚å¯ä½¿ç”¨ 'all' æˆ– 'examples' å…³é”®å­—ã€‚",
    )
    parser.add_argument(
        "--num_workers", "-w",
        default=-1,
        type=int,
        help="ä½¿ç”¨çš„è¿›ç¨‹æ•°ã€‚é»˜è®¤ä¸º -1ï¼Œä»£è¡¨ä½¿ç”¨æ‰€æœ‰ CPUæ ¸å¿ƒã€‚",
    )
    args = parser.parse_args()

    # åˆå¹¶ä½ç½®å‚æ•°å’Œå¯é€‰å‚æ•°ï¼Œä»¥å¯é€‰å‚æ•°ä¼˜å…ˆ
    files_to_parse = args.files_to_parse if args.files_to_parse else args.files
    if not files_to_parse:
         files_to_parse = ["all"] # å¦‚æœæœªæä¾›ä»»ä½•æ–‡ä»¶ï¼Œåˆ™é»˜è®¤ä¸º 'all'

    num_workers = mp.cpu_count() if args.num_workers == -1 else args.num_workers

    # --- è§£ææ–‡ä»¶è·¯å¾„ ---
    print(">>> æ­£åœ¨è§£æéœ€è¦è½¬æ¢çš„æ–‡ä»¶...")
    if files_to_parse == ["all"]:
        from pathlib import Path
        # ç¡®å®šé¡¹ç›®æ ¹ç›®å½•
        SCRIPT_DIR = Path(__file__).resolve().parent
        PROJECT_ROOT = SCRIPT_DIR.parent.parent.parent
        # ä½¿ç”¨ç»å¯¹è·¯å¾„è¿›è¡Œæœç´¢
        search_path = PROJECT_ROOT / "paddleformers/transformers/**/modular_*.py"
        files_to_parse = glob.glob(str(search_path), recursive=True)
    elif files_to_parse == ["examples"]:
        # æŸ¥æ‰¾æ‰€æœ‰ examples ç›®å½•ä¸‹çš„ modular æ–‡ä»¶
        files_to_parse = glob.glob("examples/**/modular_*.py", recursive=True)
    else:
        # å°†æ¨¡å‹ç®€ç§°ï¼ˆå¦‚ qwen2ï¼‰è§£æä¸ºå®Œæ•´è·¯å¾„
        resolved_files = []
        for model_name in files_to_parse:
            if not os.path.exists(model_name):
                # å°è¯•åœ¨ models ç›®å½•ä¸‹æ„å»ºè·¯å¾„
                full_path = os.path.join("src", "transformers", "models", model_name, f"modular_{model_name}.py")
                if not os.path.isfile(full_path):
                     # å¦‚æœæ‰¾ä¸åˆ°ï¼Œå°è¯•åœ¨ examples ç›®å½•ä¸‹æ„å»º
                    full_path = os.path.join("examples", "modular-transformers", f"modular_{model_name}.py")
                
                if not os.path.isfile(full_path):
                    raise ValueError(f"æ— æ³•ä¸º '{model_name}' æ‰¾åˆ°æ¨¡å—åŒ–æ–‡ä»¶ã€‚è¯·æä¾›å®Œæ•´è·¯å¾„æˆ–ç¡®è®¤æ–‡ä»¶åæ­£ç¡®ã€‚")
                resolved_files.append(full_path)
            else:
                resolved_files.append(model_name)
        files_to_parse = resolved_files
    
    if not files_to_parse:
        print("æœªæ‰¾åˆ°ä»»ä½•éœ€è¦è½¬æ¢çš„æ–‡ä»¶ã€‚")
        return
        
    print(f"å‘ç° {len(files_to_parse)} ä¸ªæ–‡ä»¶å¾…å¤„ç†ã€‚")

    
    ordered_files= [files_to_parse]
    print(ordered_files)

    # --- æŒ‰ä¾èµ–é¡ºåºå¹¶è¡Œå¤„ç† ---
    for i, dependency_level_files in enumerate(ordered_files):
        print(f"\n>>> å¼€å§‹å¤„ç†ä¾èµ–å±‚çº§ {i+1}/{len(ordered_files)} ({len(dependency_level_files)} ä¸ªæ–‡ä»¶)...")
        workers = min(num_workers, len(dependency_level_files))
        if workers > 0:
            with mp.Pool(workers) as pool:
                pool.map(run_converter, dependency_level_files)
    
    print("\n--- æ‰€æœ‰è½¬æ¢ä»»åŠ¡å·²å®Œæˆ ---")


if __name__ == "__main__":
    main()